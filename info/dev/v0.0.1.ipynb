{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DataClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from abc import abstractmethod, ABCMeta\n",
    "\n",
    "\n",
    "class DataClass(metaclass=ABCMeta):\n",
    "    _test_line: str = \"none\"\n",
    "    is_request_control: bool = False\n",
    "    _fmt = None\n",
    "    _slice = None\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def patterns(self) -> List[re.Pattern]:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def data(self):\n",
    "        pass\n",
    "\n",
    "    def decode_line(self, line: str):\n",
    "        if self.is_request_control:\n",
    "            if self._check_is_endline(line=line):\n",
    "                self.is_request_control = False\n",
    "                self.data = np.array(self._tmp_data).astype(self._fmt)\n",
    "                del self._tmp_data\n",
    "            else:\n",
    "                self._tmp_data.append(line.split()[self._slice])\n",
    "        else:\n",
    "            for pattern in self.patterns:\n",
    "                if data := pattern.match(line):\n",
    "                    self._inner_match_patterns(data=data)\n",
    "                    break\n",
    "\n",
    "    @abstractmethod\n",
    "    def _inner_match_patterns(self, data):\n",
    "        pass\n",
    "\n",
    "    def _check_is_endline(self, line: str) -> bool:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(DataClass):\n",
    "    patterns = [re.compile(r\"\\s+[^0-9]+\\|\\s+Cell lengths\\s+\\[ang\\]\\s+(?P<x>\\S+)\\s+(?P<y>\\S+)\\s+(?P<z>\\S+)\\s+\")]\n",
    "    data = np.zeros(3, dtype=float)\n",
    "    _fmt = float\n",
    "\n",
    "    def _inner_match_patterns(self, data):\n",
    "        self.data = np.array([data[\"x\"], data[\"y\"], data[\"z\"]]).astype(self._fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Energy(DataClass):\n",
    "    patterns = [re.compile(r\"\\s+ENERGY\\|\\s+Total\\s+FORCE_EVAL\\s+\\(\\s+QS\\s+\\)\\s+energy\\s+\\[a.u.\\]\\:\\s+(?P<energy>\\S+)\\s+\")]\n",
    "    data = 0.0\n",
    "    _fmt = float\n",
    "\n",
    "    def _inner_match_patterns(self, data):\n",
    "        self.data = np.array([data[\"energy\"]]).astype(self._fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atom(DataClass):\n",
    "    patterns = [re.compile(r\"\\s+Atom\\s+Kind\\s+Element\\s+X\\s+Y\\s+Z\\s+Z\\(eff\\)\\s+\")]\n",
    "    data = np.zeros([10], dtype=float)\n",
    "    _fmt = \"<U4\"\n",
    "    _slice = slice(2, 3)\n",
    "\n",
    "    def _inner_match_patterns(self, data):\n",
    "        self.is_request_control = True\n",
    "        self._tmp_data = []\n",
    "\n",
    "    def _check_is_endline(self, line: str) -> bool:\n",
    "        return line.strip() == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Force(DataClass):\n",
    "    patterns = [re.compile(\"\\s+\\#\\s+Atom\\s+Kind\\s+Element\\s+X\\s+Y\\s+\")]\n",
    "    data = np.zeros([1, 3], dtype=float)\n",
    "    _fmt = float\n",
    "    _slice = slice(3, 6)\n",
    "\n",
    "    def _inner_match_patterns(self, data):\n",
    "        self.is_request_control = True\n",
    "        self._tmp_data = []\n",
    "\n",
    "    def _check_is_endline(self, line: str) -> bool:\n",
    "        return line.startswith(\" SUM OF ATOMIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stress(DataClass):\n",
    "    patterns = [re.compile(\"\\s+STRESS\\|\\s+x\\s+y\\s+\")]\n",
    "    data = np.zeros([1, 3], dtype=float)\n",
    "    _fmt = float\n",
    "    _slice = slice(2, 5)\n",
    "\n",
    "    def _inner_match_patterns(self, data):\n",
    "        self.is_request_control = True\n",
    "        self._tmp_data = []\n",
    "\n",
    "    def _check_is_endline(self, line: str) -> bool:\n",
    "        return line.startswith(\" STRESS| 1/3 Trace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogOpener:\n",
    "    _end_patterns = [\"\\s+Extrapolation method:\\s+ASPC\\s+\", \"\\s+\\-\\s+DBCSR STATISTICS\\s+\\-\\s+\"]\n",
    "\n",
    "    def __init__(self, logfile: str) -> None:\n",
    "        self._frame = -1\n",
    "        self.logdata_generator = self._generate_data_from_logfile(logfile=logfile)\n",
    "        self.nextframe()\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return {key: dataclass.data for key, dataclass in self.dataclasses.items()}\n",
    "\n",
    "    @property\n",
    "    def end_patterns(self) -> List[re.Pattern]:\n",
    "        return [re.compile(ep) for ep in self._end_patterns]\n",
    "\n",
    "    @end_patterns.setter\n",
    "    def end_patterns(self, patterns):\n",
    "        self._end_patterns = patterns\n",
    "\n",
    "    @property\n",
    "    def frame(self) -> int:\n",
    "        return self._frame\n",
    "\n",
    "    def _generate_data_from_logfile(self, logfile: str):\n",
    "        self.reset_dataclasses()\n",
    "        with open(logfile, \"r\") as f:\n",
    "            while this_line := f.readline():\n",
    "                for end_pattern in self.end_patterns:\n",
    "                    if end_pattern.match(this_line):\n",
    "                        yield self.dataclasses\n",
    "                for key, dataclass in self.dataclasses.items():\n",
    "                    dataclass.decode_line(line=this_line)\n",
    "\n",
    "    def reset_dataclasses(self) -> dict[str, DataClass]:\n",
    "        self.dataclasses = {\"cell\": Cell(), \"energy\": Energy(), \"atom\": Atom(), \"force\": Force(), \"stress\": Stress()}\n",
    "\n",
    "    def nextframe(self):\n",
    "        self.dataclasses = next(self.logdata_generator)\n",
    "        self._frame += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Trj Opener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from typing import TextIO\n",
    "\n",
    "\n",
    "class TrjOpener(metaclass=ABCMeta):\n",
    "    skip_head: int = 0\n",
    "\n",
    "    def __init__(self, trjfile: str) -> None:\n",
    "        self._frame = -1\n",
    "        self._energy = None\n",
    "        self._coords = None\n",
    "        self.trjdata_generator = self._generate_trjdata(trjfile=trjfile)\n",
    "        self.nextframe()\n",
    "\n",
    "    @property\n",
    "    def natoms(self) -> int:\n",
    "        return int(self._natoms)\n",
    "\n",
    "    @property\n",
    "    def coords(self):\n",
    "        return np.array(self._coords).astype(float)\n",
    "\n",
    "    @property\n",
    "    def energy(self):\n",
    "        return np.array([self._energy]).astype(float)\n",
    "\n",
    "    @property\n",
    "    def frame(self) -> int:\n",
    "        return self._frame\n",
    "\n",
    "    def nextframe(self) -> None:\n",
    "        self._frame += 1\n",
    "        next(self.trjdata_generator)\n",
    "\n",
    "    def _generate_trjdata(self, trjfile: str):\n",
    "        with open(trjfile, \"r\") as f:\n",
    "            [f.readline() for _ in range(self.skip_head)]\n",
    "            while True:\n",
    "                try:\n",
    "                    yield self._inner_generate_trjdata(file=f)\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "    @abstractmethod\n",
    "    def _inner_generate_trjdata(self, file: TextIO):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XYZOpener(TrjOpener):\n",
    "    def _inner_generate_trjdata(self, file):\n",
    "        self._natoms = int(file.readline().strip())\n",
    "        self._energy = file.readline().split()[-1]\n",
    "        self._coords = [file.readline().split()[1:4] for _ in range(self._natoms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDBOpener(TrjOpener):\n",
    "    skip_head = 2\n",
    "\n",
    "    def _inner_generate_trjdata(self, file):\n",
    "        self._energy = file.readline().split()[-1]\n",
    "        file.readline()\n",
    "        coords = []\n",
    "        while this_line := file.readline():\n",
    "            if this_line.startswith(\"END\"):\n",
    "                break\n",
    "            coords.append(this_line.split()[3:6])\n",
    "        self._coords = coords\n",
    "        self._natoms = len(coords)\n",
    "        del coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1. TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "trjopener: dict[str, type[TrjOpener]] = {\n",
    "    \"xyz\": XYZOpener,\n",
    "    \"pdb\": PDBOpener,\n",
    "}\n",
    "\n",
    "\n",
    "class CP2kBrewer(object):\n",
    "    def __init__(self, logfile: str, trjfile: str, *, trjformat: str = \"auto\") -> None:\n",
    "        self.log_opener = LogOpener(logfile=logfile)\n",
    "        self.trjformat = self._check_trjformat(trjfile=trjfile, trjformat=trjformat)\n",
    "        self.trj_opener = trjopener[self.trjformat](trjfile=trjfile)\n",
    "\n",
    "    def _check_trjformat(self, trjfile, trjformat):\n",
    "        if trjformat == \"auto\":\n",
    "            return trjfile.split(\".\")[-1]\n",
    "        return trjformat\n",
    "\n",
    "    @property\n",
    "    def frame(self) -> int:\n",
    "        assert (\n",
    "            self.log_opener.frame == self.trj_opener.frame\n",
    "        ), f\"Frame of Openers are different, LOG({self.log_opener.frame}) != TRJ({self.trj_opener.frame})\"\n",
    "        return self.log_opener.frame\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        _data = self.log_opener.data\n",
    "        _data[\"coords\"] = self.trj_opener.coords\n",
    "        assert (\n",
    "            abs(_data[\"energy\"] - self.trj_opener.energy) < 1e-7\n",
    "        ), f\"Energy are different at Frame {self.frame}, LOG({_data['energy']}) != TRJ({self.trj_opener.energy})\"\n",
    "        return _data\n",
    "\n",
    "    @property\n",
    "    def gathered_data(self):\n",
    "        if not hasattr(self, \"_gathered_data\"):\n",
    "            self.gather()\n",
    "        return self._gathered_data\n",
    "\n",
    "    def gather(self, *, verbose: bool = True):\n",
    "        if verbose:\n",
    "            pbar = tqdm()\n",
    "        _data = {key: [val] for key, val in self.data.items()}\n",
    "        while True:\n",
    "            try:\n",
    "                self.nextframe()\n",
    "                for key, val in self.data.items():\n",
    "                    _data[key].append(val)\n",
    "                if verbose:\n",
    "                    pbar.update(n=1)\n",
    "            except:\n",
    "                break\n",
    "        _data = {key: np.array(val) for key, val in _data.items()}\n",
    "        self._gathered_data = _data\n",
    "        return self._gathered_data\n",
    "\n",
    "    def nextframe(self):\n",
    "        self.log_opener.nextframe()\n",
    "        self.trj_opener.nextframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMT: xyz\n",
      "TRJ OPENER: <__main__.XYZOpener object at 0x118f6e770>\n",
      "TRJ OPENER nAtoms: 192\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logfile = \"/Users/minu/local_git/cp2kbrew/src/2022.2/npt/out.log\"\n",
    "    trjfile = \"/Users/minu/local_git/cp2kbrew/src/2022.2/npt/TEST-pos-1.xyz\"\n",
    "    pdbfile = \"../src/trj/test.pdb\"\n",
    "\n",
    "    cp2kbrewer = CP2kBrewer(logfile=logfile, trjfile=trjfile)\n",
    "    print(f\"FMT: {cp2kbrewer.trjformat}\")\n",
    "    print(f\"TRJ OPENER: {cp2kbrewer.trj_opener}\")\n",
    "    print(f\"TRJ OPENER nAtoms: {cp2kbrewer.trj_opener.natoms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:01, 449.06it/s]\n"
     ]
    }
   ],
   "source": [
    "cp2kbrewer = CP2kBrewer(logfile=logfile, trjfile=trjfile)\n",
    "data = cp2kbrewer.gather(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell    : (501, 3)\n",
      "energy  : (501, 1)\n",
      "atom    : (501, 192, 1)\n",
      "force   : (501, 192, 3)\n",
      "stress  : (501, 3, 3)\n",
      "coords  : (501, 192, 3)\n"
     ]
    }
   ],
   "source": [
    "for key, val in data.items():\n",
    "    print(f\"{key:<8s}: {val.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp2kbrew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
